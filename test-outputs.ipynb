{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of Project Outputs\n",
    "### Project 4 : Data Lakes in Spark\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load AWS credentials as env vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "# parse config file\n",
    "config.read('dl.cfg') #Normally this file should be in ~/.aws/credentials\n",
    "\n",
    "# set environment variables\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['KEY']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['SECRET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create spark session with hadoop-aws package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.5\")\\\n",
    "                     .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Verify Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      "\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "|           song_id|               title| duration|year|         artist_id|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "|SOBTCUI12A8AE48B70|Faust: Ballet Mus...| 94.56281|   0|ARSUVLW12454A4C8B8|\n",
      "|SOVNKJI12A8C13CB0D|Take It To Da Hou...|227.10812|2001|ARWUNH81187FB4A3E0|\n",
      "|SOYVBGZ12A6D4F92A8|Piano Sonata No. ...|221.70077|   0|ARLRWBW1242077EB29|\n",
      "|SODBHKO12A58A77F36|Fingers Of Love (...|335.93424|   0|ARKGS2Z1187FB494B5|\n",
      "|SOGXFIF12A58A78CC4|Hanging On (Mediu...|204.06812|   0|AR5LZJD1187FB4C5E5|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"analytics/songs/songs.parquet\")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      "\n",
      "+------------------+---------------+--------------------+--------+----------+\n",
      "|         artist_id|         artist|            location|latitude| longitude|\n",
      "+------------------+---------------+--------------------+--------+----------+\n",
      "|AR3WWZM1187B996646|Weeping Willows|       Massachusetts|42.18419| -71.71818|\n",
      "|AR8Y6HV1187FB5546D|     Danny Byrd|                  UK|54.31407|  -2.23001|\n",
      "|ARBJQTM1187B9B862B|  Cocteau Twins|Grangemouth, Scot...|56.01162|  -3.71947|\n",
      "|ARBM57Q1187B9AF97C|   James Horner|     Los Angeles, CA|34.05349|-118.24532|\n",
      "|ARDNS031187B9924F0|     Tim Wilson|             Georgia|32.67828| -83.22295|\n",
      "+------------------+---------------+--------------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"analytics/artists/artists.parquet\")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      "\n",
      "+------+---------+---------+------+-----+\n",
      "|userId|firstName| lastName|gender|level|\n",
      "+------+---------+---------+------+-----+\n",
      "|    88| Mohammad|Rodriguez|     M| free|\n",
      "|    53|  Celeste| Williams|     F| free|\n",
      "|    75|   Joseph|Gutierrez|     M| free|\n",
      "|    60|    Devin|   Larson|     M| free|\n",
      "|    68|   Jordan|Rodriguez|     F| free|\n",
      "+------+---------+---------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"analytics/users/users.parquet\")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "+--------------------+----+---+----+----+-----+\n",
      "|          start_time|hour|day|week|year|month|\n",
      "+--------------------+----+---+----+----+-----+\n",
      "|2018-11-15 16:36:...|  16| 15|  46|2018|   11|\n",
      "|2018-11-15 19:02:...|  19| 15|  46|2018|   11|\n",
      "|2018-11-21 15:26:...|  15| 21|  47|2018|   11|\n",
      "|2018-11-21 17:55:...|  17| 21|  47|2018|   11|\n",
      "|2018-11-21 18:49:...|  18| 21|  47|2018|   11|\n",
      "+--------------------+----+---+----+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"analytics/time/time.parquet\")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "+--------------------+------+-----+------------------+------------------+---------+--------------------+--------------------+----+-----+\n",
      "|          start_time|userId|level|           song_id|         artist_id|sessionId|            location|           userAgent|year|month|\n",
      "+--------------------+------+-----+------------------+------------------+---------+--------------------+--------------------+----+-----+\n",
      "|2018-11-21 21:56:...|    15| paid|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4|      818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "|2018-11-05 17:49:...|    73| paid|SOHDWWH12A6D4F7F6A|ARC0IOF1187FB3F6E6|      255|Tampa-St. Petersb...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "|2018-11-13 22:39:...|    55| free|SOXQYSC12A6310E908|AR0L04E1187B9AE90C|      415|Minneapolis-St. P...|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "|2018-11-16 14:21:...|    85| paid|SOLRYQR12A670215BF|ARNLO5S1187B9B80CC|      436|       Red Bluff, CA|\"Mozilla/5.0 (Mac...|2018|   11|\n",
      "|2018-11-20 17:46:...|    49| paid|SOCHRXB12A8AE48069|ARTDQRC1187FB4EFD4|      758|San Francisco-Oak...|Mozilla/5.0 (Wind...|2018|   11|\n",
      "+--------------------+------+-----+------------------+------------------+---------+--------------------+--------------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"analytics/songplays/songplays.parquet\")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
